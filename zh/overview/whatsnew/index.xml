<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Apache Dubbo – 3.0 速览</title><link>https://dubbo.apache.org/zh/overview/whatsnew/</link><description>Recent content in 3.0 速览 on Apache Dubbo</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://dubbo.apache.org/zh/overview/whatsnew/index.xml" rel="self" type="application/rss+xml"/><item><title>Overview: 背景</title><link>https://dubbo.apache.org/zh/overview/whatsnew/background/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dubbo.apache.org/zh/overview/whatsnew/background/</guid><description>
&lt;p>Dubbo3 的设计与开发有两个大的背景。&lt;/p>
&lt;p>&lt;strong>首先，如何更好的满足企业实践诉求。&lt;/strong> Dubbo 自 2011 由阿里巴巴捐献开源以来，一直是众多大型企业微服务实践的首选开源服务框架。在此期间，企业架构经历了从 SOA 架构到微服务架构变迁，Dubbo 社区自身也在不断的更新迭代以更好的满足企业诉求。然而 Dubbo2 架构上的局限逐渐在实践中凸显：1.协议，Dubbo2 协议以性能、简洁著称，但却在云原生时代遇到越来越多的通用性、穿透性问题；2.可伸缩性，Dubbo2 在可伸缩性上依旧远超很多其他框架，但随着微服务带来更多应用与实例我们不得不思考如何应对更大规模集群的实战；3.服务治理易用性，如更丰富的流量治理、可观测性、智能负载均衡等。&lt;/p>
&lt;p>&lt;strong>其次，适配云原生技术栈的发展。&lt;/strong> 微服务让业务开发演进更灵活、快捷的同时，也带来了一些它独有的特征和需求：如微服务之后组件数量越来越多，如何解决各个组件的稳定性，如何快速的水平扩容等，以 Docker、Kubernetes、Service Mesh 为代表的云原生基础设施为解决这些问题带来了一些新的选择。随着更多的微服务组件及能力正下沉到以 Kubernetes 为代表的基础设施层，传统微服务开发框架应剔除一些冗余机制，积极的适配到基础设施层以做到能力复用，微服务框架生命周期、服务治理等能力应更好地与 Kubernetes 服务编排机制融合； 以 Service Mesh 为代表微服务架构给微服务开发带来的新的选择，Sidecar 给多语言、透明升级、流量管控等带来的优势，但同时也带来运维复杂性、性能损耗等弊端，因此基于服务框架的传统微服务体系还将是主流，长期仍将占据半壁江山，在长时间内将会维持混合部署将会维持混合部署状态。&lt;/p>
&lt;h3 id="总体目标">总体目标&lt;/h3>
&lt;p>Dubbo3 依旧保持了 2.x 的经典架构，以解决微服务进程间通信为主要职责，通过丰富的服务治理（如地址发现、流量管理等）能力来更好的管控微服务集群；Dubbo3 对原有框架的升级是全面的，体现在核心 Dubbo 特性的几乎每个环节，通过升级实现了稳定性、性能、伸缩性、易用性的全面提升。&lt;/p>
&lt;p>&lt;img src="https://dubbo.apache.org/imgs/v3/concepts/architecture-1.png" alt="architecture-1">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>通用的通信协议。&lt;/strong> 全新的 RPC 协议应摒弃私有协议栈，以更通用的 HTTP/2 协议为传输层载体，借助 HTTP 协议的标准化特性，解决流量通用性、穿透性等问题，让协议能更好的应对前后端对接、网关代理等场景；支持 Stream 通信模式，满足不同业务通信模型诉求的同时给集群带来更大的吞吐量。&lt;/li>
&lt;li>&lt;strong>面向百万集群实例，集群高度可伸缩。&lt;/strong> 随着微服务实践的推广，微服务集群实例的规模也在不停的扩展，这得益于微服务轻量化、易于水平扩容的特性，同时也给整个集群容量带来了负担，尤其是一些中心化的服务治理组件；Dubbo3 需要解决实例规模扩展带来的种种资源瓶颈问题，实现真正的无限水平扩容。&lt;/li>
&lt;li>&lt;strong>更丰富的编程模型，更小的业务侵入。&lt;/strong> 在开发态业务应用面向 Dubbo SDK 编程，在运行态 SDK 与业务应用运行在同一个进程，SDK 的易用性、稳定性与资源消耗将在很大程度上影响业务应用；因此 3.0 应该具备更抽象的 API、更友好的配置模式、更少的侵占业务应用资源、具备更高的可用性。&lt;/li>
&lt;li>&lt;strong>更易用、更丰富的服务治理能力。&lt;/strong> 微服务的动态特性给治理工作带来了很高的复杂性，而 Dubbo 这方面一直做的不错，是最早的一批治理能力定义者与实践者；3.0 需面向更丰富的场景化，提供诸如可观测性、安全性、灰度发布、错误注入、外部化配置、统一的治理规则等能力。&lt;/li>
&lt;li>&lt;strong>全面拥抱云原生。&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h3 id="面向企业生产实践痛点">面向企业生产实践痛点&lt;/h3>
&lt;p>Dubbo2 仍旧是国内首选开源服务框架，被广泛应用在互联网、金融保险、软件企业、传统企业等几乎所有数字化转型企业中，久经规模化生产环境检验。以 Dubbo2 的贡献者和典型用户阿里巴巴为例，阿里巴巴基于 Dubbo2 在内部维护的 HSF2 框架经历了历次双十一峰值考验，每天数十亿次的 RPC 调用，治理着超过千万的服务实例。在长期的优化和实践积累中，阿里巴巴有了对下一代服务框架的设想与方案，在内部开始了快速演进，并快速的被贡献到 Apache 社区，如同阿里巴巴一样，其他用户的实践诉求与痛点也在开源社区快速的积累，形成了一致的方向和技术方案，可以说 Dubbo3 的诞生就来自于超大基数的企业用户积累，为了更好的满足他们的实践诉求。&lt;/p>
&lt;p>&lt;img src="https://dubbo.apache.org/imgs/v3/concepts/dubbo-hsf.png" alt="dubbo3-hsf">&lt;/p>
&lt;p>Dubbo3 融合了阿里巴巴 HSF2 及其他社区企业的大量服务治理经验，当前 Dubbo3 已经被全面应用到生产实践环境，用户包括阿里巴巴电商、饿了么、钉钉、考拉、阿里云、小米、工商银行、风火递、平安健康等。社区与用户的合作形成的良性循环极大的促进了 Dubbo3 的发展，阿里巴巴已经以社区版 Dubbo3 完全取代了内部维护的 HSF2 框架，他们的实践经验一方面推动 Dubbo3 的稳定性，另一方面正够源源不断的将服务治理实践经验输出到开源社区。&lt;/p>
&lt;h3 id="面向百万集群实例横向可扩容">面向百万集群实例，横向可扩容&lt;/h3>
&lt;p>随着微服务实践经验的积累，微服务被拆分成更细粒度，部署到越来越多的机器实例，以支撑不断增长的业务规模。在众多的 Dubbo2 企业用户中，尤其是以金融保险、互联网为代表的规模化企业开始遇到集群容量瓶颈问题（典型的请参照&lt;a href="https://dubbo.apache.org/zh/users/icbc/">工商银行实践案例&lt;/a>）：&lt;/p>
&lt;ul>
&lt;li>服务发现过程
&lt;ul>
&lt;li>注册中心数据存储规模达到容量瓶颈&lt;/li>
&lt;li>数据注册&amp;amp;推送效率严重下降&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Dubbo 进程
&lt;ul>
&lt;li>侵占更多机器资源，导致业务资源利用率降低&lt;/li>
&lt;li>频繁 GC 影响业务稳定性&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Dubbo3 在设计上很好的解决了这些问题，通过全新设计实现的服务治理（服务发现）模型，可以实现服务发现链路上的数据传输、数据存储量平均下降 90% 左右；同时 Dubbo3 自身在业务进程中变得更轻量、更稳定，实现提升资源利用率 50%。&lt;/p>
&lt;p>Dubbo3 一个更大的优势在于其对整体架构稳定性的提升，新的服务发现架构使得对于整个集群容量、可伸缩性评估变得更容易、更准确。&lt;/p>
&lt;p>&lt;img src="https://dubbo.apache.org/imgs/v3/concepts/capacity.png" alt="capacity">&lt;/p>
&lt;p>如果将应用开发粗略划分为业务开发、运维部署两个层次，其中变化比较频繁的因素包括服务（接口）、应用、机器实例。在 2.x 时代，所有这三个因素的增长都会影响微服务集群的总体容量，尤其是接口增减带来的波动，对整体容量评估是非常不透明的。而在 3.0 中集群容量变化仅与应用名、机器实例两个因素相关，而我们容量评估的对象往往都是应用与实例，因此整个集群集群变的更稳定透明。&lt;/p>
&lt;h3 id="云原生">云原生&lt;/h3>
&lt;p>在云原生时代，底层基础设施的变革正深刻影响应用的部署、运维甚至开发过程，往上也影响了 Dubbo3 微服务技术方案的选型与部署模式。&lt;/p>
&lt;h4 id="下一待-rpc-协议">下一待 RPC 协议&lt;/h4>
&lt;p>新一代的 Triple 协议基于 HTTP/2 作为传输层，具备更好的网关、代理穿透性，原生支持 Stream 通信语义，兼容 gRPC 协议。&lt;/p>
&lt;h4 id="多语言友好">多语言友好&lt;/h4>
&lt;p>Dubbo3 从服务定义、RPC 协议、序列化、服务治理等多个方面都已经将多语言友好性作为重点考量因素，目前提供了 Java、Golang 稳定的多语言版本，更多语言版本的 3.0 实现如 Rust、Javascript、C/C++、C# 等在开发建设中。&lt;/p>
&lt;h4 id="kubernetes">Kubernetes&lt;/h4>
&lt;p>Dubbo3 开发的应用可以原生部署到 Kubernetes 平台，Dubbo3 在地址、生命周期等已设计可与 Kubernetes 等容器调度平台对齐；对于要进一步复用 Kubernetes 底层基础设施能力的用户来说，Dubbo3 也已对接到了原生的 Kubernetes Service 体系。&lt;/p>
&lt;h4 id="service-mesh">Service Mesh&lt;/h4>
&lt;p>Service Mesh 强调控制面在微服务治理中的作用，在一定程度上推动了控制面通信协议、职责范围的扩展与标准化；传统 Mesh 架构下的 Sidecar 模型强调旁路代理对于流量的统一管控，以实现透明升级、多语言无感、无业务侵入等特性。&lt;/p>
&lt;p>Dubbo3 提供了基于自身思考的 Dubbo Mesh 解决方案，强调了控制面对微服务集群的统一管控，而在部署架构上，同时支持 sicecar 与无 sidecar 的 proxyless 部署架构，使用 Dubbo Mesh 的用户基于自身的业务特点将有更多的部署架构选择。&lt;/p>
&lt;h4 id="异构体系互通">异构体系互通&lt;/h4>
&lt;p>我们正看到越来越多的异构微服务体系互通的诉求，典型如 Dubbo、Spring Cloud、gRPC 等。有些是因为技术栈迁移，有些是组织合并后需要实现业务互调，Dubbo3 借助于新的服务发现模型以及可灵活扩展的 RPC 协议，可以成为&lt;/p></description></item><item><title>Overview: Triple 协议</title><link>https://dubbo.apache.org/zh/overview/whatsnew/triple/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dubbo.apache.org/zh/overview/whatsnew/triple/</guid><description>
&lt;p>Triple 是 Dubbo3 提出的基于 HTTP2 的开放协议，旨在解决 Dubbo2 私有协议带来的互通性问题。相比于原有 Dubbo2 协议，Triple 有以下优势:&lt;/p>
&lt;ol>
&lt;li>原生和 gRPC 协议互通。打通 gRPC 生态，降低从 gRPC 至 Dubbo 的迁移成本。&lt;/li>
&lt;li>增强多语言生态。避免因 CPP/C#/RUST 等语言的 Dubbo SDK 能力不足导致业务难以选型适配的问题。&lt;/li>
&lt;li>网关友好。网关无需参与序列化，方便用户从传统的 HTTP 转泛化 Dubbo 调用网关升级至开源或云厂商的 Ingress 方案。&lt;/li>
&lt;li>完善的异步和流式支持。带来从底层协议到上层业务的性能提升，易于构建全链路异步以及严格保证消息顺序的流式服务。&lt;/li>
&lt;/ol>
&lt;p>目前 Java 和 Go 的 Dubbo SDK 已全面支持 Triple 协议。在阿里巴巴，Triple 协议广泛用于跨环境、跨语言、跨生态互通，已有数十万容器生产级使用。&lt;/p>
&lt;p>Java SDK 支持 &lt;a href="../../../docs3-v2/java-sdk/quick-start/idl">IDL 生成 Stub&lt;/a>
和 &lt;a href="../../../docs3-v2/java-sdk/quick-start/idl">Java Interface&lt;/a> 两种方式，多语言、生态互通、流式需求推荐使用 IDL 方式，现有服务平滑升级推荐使用
Interface 方式。&lt;/p>
&lt;ul>
&lt;li>Dubbo2 老用户如何从现有协议升级至 Triple(TBD)&lt;/li>
&lt;li>新用户或业务参考&lt;a href="../../../docs3-v2/java-sdk/quick-start/idl/">Dubbo3 Triple Quick Start&lt;/a>&lt;/li>
&lt;li>深入了解 Triple 协议:&lt;a href="https://github.com/apache/dubbo-awesome/blob/master/proposals/D0-triple.md">Dubbo3 Triple 协议设计与原理&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Overview: 应用级服务发现</title><link>https://dubbo.apache.org/zh/overview/whatsnew/service-discovery/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dubbo.apache.org/zh/overview/whatsnew/service-discovery/</guid><description>
&lt;p>在这里查看更多文档&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/apache/dubbo-awesome/blob/master/proposals/D1-application-level-service-discovery.md">应用级服务发现详细设计&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dubbo.apache.org/zh/blog/2021/06/02/dubbo3-%E5%BA%94%E7%94%A8%E7%BA%A7%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/">应用级服务发现解读 (blog)&lt;/a>&lt;/li>
&lt;li>&lt;a href="../../../docs3-v2/java-sdk/upgrades-and-compatibility/service-discovery/migration-service-discovery">如何从接口级服务发现迁移到应用级服务发现&lt;/a>&lt;/li>
&lt;li>&lt;a href="../../../users/eleme">饿了么应用级服务发现实践&lt;/a>&lt;/li>
&lt;li>&lt;a href="../../../users/icbc">工商银行应用级服务发现实践&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>概括来说，Dubbo3 引入的应用级服务发现主要有以下优势&lt;/p>
&lt;ul>
&lt;li>适配云原生微服务变革。云原生时代的基础设施能力不断向上释放，像 Kubernetes 等平台都集成了微服务概念抽象，Dubbo3 的应用级服务发现是适配各种微服务体系的通用模型。&lt;/li>
&lt;li>提升性能与可伸缩性。支持超大规模集群的服务治理一直以来都是 Dubbo 的优势，通过引入应用级服务发现模型，从本质上解决了注册中心地址数据的存储与推送压力，相应的 Consumer 侧的地址计算压力也成数量级下降；集群规模也开始变得可预测、可评估（与 RPC 接口数量无关，只与实例部署规模相关）。&lt;/li>
&lt;/ul>
&lt;p>下图是 Dubbo2 的服务发现模型：Provider 注册服务地址，Consumer 经过注册中心协调并发现服务地址，进而对地址发起通信，这是被绝大多数微服务框架的经典服务发现流程。而 Dubbo2 的特殊之处在于，它把 “RPC 接口”的信息也融合在了地址发现过程中，而这部分信息往往是和具体的业务定义密切相关的。&lt;/p>
&lt;p>&lt;img src="https://dubbo.apache.org/imgs/v3/concepts/servicediscovery_old.png" alt="//imgs/v3/concepts/servicediscovery_old.png">&lt;/p>
&lt;p>而在接入云原生基础设施后，基础设施融入了微服务概念的抽象，容器化微服务被编排、调度的过程即完成了在基础设施层面的注册。如下图所示，基础设施既承担了注册中心的职责，又完成了服务注册的动作，而 “RPC 接口”这部分信息，由于与具体的业务相关，不可能也不适合被基础设施托管。&lt;/p>
&lt;p>&lt;img src="https://dubbo.apache.org/imgs/v3/concepts/servicediscovery_k8s.png" alt="//imgs/v3/concepts/servicediscovery_k8s.png">&lt;/p>
&lt;p>在这样的场景下，对 Dubbo3 的服务注册发现机制提出了两个要求：
Dubbo3 需要在原有服务发现流程中抽象出通用的、与业务逻辑无关的地址映射模型，并确保这部分模型足够合理，以支持将地址的注册行为和存储委托给下层基础设施
Dubbo3 特有的业务接口同步机制，是 Dubbo3 需要保留的优势，需要在 Dubbo3 中定义的新地址模型之上，通过框架内的自有机制予以解决。&lt;/p>
&lt;p>这样设计的全新的服务发现模型，在架构兼容性、可伸缩性上都给 Dubbo3 带来了更大的优势。&lt;/p>
&lt;p>&lt;img src="https://dubbo.apache.org/imgs/v3/concepts/servicediscovery_mem.png" alt="//imgs/v3/concepts/servicediscovery_mem.png">&lt;/p>
&lt;p>在架构兼容性上，如上文所述，Dubbo3 复用下层基础设施的服务抽象能力成为了可能；另一方面，如 Spring Cloud 等业界其它微服务解决方案也沿用这种模型，
在打通了地址发现之后，使得用户探索用 Dubbo 连接异构的微服务体系成为了一种可能。&lt;/p>
&lt;p>Dubbo3 服务发现模型更适合构建可伸缩的服务体系，这点要如何理解？
这里先举个简单的例子，来直观的对比 Dubbo2 与 Dubbo3 在地址发现流程上的数据流量变化：假设一个微服务应用定义了 100 个接口（Dubbo 中的服务），
则需要往注册中心中注册 100 个服务，如果这个应用被部署在了 100 台机器上，那这 100 个服务总共会产生 100 * 100 = 10000 个虚拟节点；而同样的应用，
对于 Dubbo3 来说，新的注册发现模型只需要 1 个服务（只和应用有关和接口无关）， 只注册和机器实例数相等的 1 * 100 = 100 个虚拟节点到注册中心。
在这个简单的示例中，Dubbo 所注册的地址数量下降到了原来的 1 / 100，对于注册中心、订阅方的存储压力都是一个极大的释放。更重要的是，
地址发现容量彻底与业务 RPC 定义解耦开来，整个集群的容量评估对运维来说将变得更加透明：部署多少台机器就会有多大负载，不会像 Dubbo2 一样，
因为业务 RPC 重构就会影响到整个集群服务发现的稳定性。&lt;/p></description></item><item><title>Overview: Dubbo Mesh</title><link>https://dubbo.apache.org/zh/overview/whatsnew/mesh/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dubbo.apache.org/zh/overview/whatsnew/mesh/</guid><description>
&lt;p>Dubbo Mesh 从设计理念上更强调控制面的统一管控、标准化与治理能力，而在数据面给出了更多的选择，包括 Sidecar Mesh 与 Proxyless Mesh 等部署模式。多种部署模型给企业提供了更多选择，通过混合部署的模型，在实现服务治理控制面的共享的同时，可以更好的应对不同场景的部署要求（性能、部署复杂性等），适应复杂的基础设施环境并从总体上提升架构的可用性。&lt;/p>
&lt;h2 id="背景">背景&lt;/h2>
&lt;p>在云原生背景下，如果我们将 Service Mesh 理解为底层基础设施，则在 Mesh 架构中，以往耦合在业务进程中的微服务治理部分能力正被 Mesh 接管，传统微服务框架更注重 RPC 协议与编程模型。以下是时下流行的 Mesh 产品 Istio 的架构图：&lt;/p>
&lt;p>&lt;img src="https://dubbo.apache.org/imgs/v3/mesh/istio.jpg" alt="istio">&lt;/p>
&lt;p>在 Mesh 架构下&lt;/p>
&lt;ul>
&lt;li>统一的控制面提供证书管理、可观测性、流量治理等能力&lt;/li>
&lt;li>Sidecar 让 SDK 更轻量、侵入性更小，更好的实现透明升级、流量拦截等&lt;/li>
&lt;/ul>
&lt;h2 id="dubbo-mesh-总体架构">Dubbo Mesh 总体架构&lt;/h2>
&lt;p>&lt;img src="https://dubbo.apache.org/imgs/v3/mesh/dubbo-mesh-arc.png" alt="istio">&lt;/p>
&lt;ul>
&lt;li>数据面基于 Triple 协议进行 RPC 通信；&lt;/li>
&lt;li>地址发现模型采用应用级服务发现，支持超大规模实例集群的同时，提供更丰富的服务治理能力；&lt;/li>
&lt;li>Dubbo Mesh 控制面基于业界主流 Istio 扩展，支持 Dubbo 服务发现定制方案，同时提供更丰富的流量管控能力，；&lt;/li>
&lt;li>数据面支持两种模式：ThinSDK + Sidecar(如 Envoy) 和 Proxyless；&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>对于 Dubbo2 老用户或已升级 Dubbo3 但尚未迁移新特性的用户，可以考虑参考其他 Mesh 开源社区（如 Aeraki）提供的 Dubbo 方案。
但部分功能可能受限，同时会有一定的性能和容量瓶颈。&lt;/p>
&lt;/blockquote>
&lt;h3 id="dubbo-sidecar-mesh">Dubbo Sidecar Mesh&lt;/h3>
&lt;p>Dubbo 提供了 ThinSDK 的部署模式，在此模式下，Dubbo ThinSDK 将只提供面向业务应用的编程 API、RPC 传输通信能力，其余服务治理
包括地址发现、负载均衡、路由寻址等都统一下沉到 Sidecar，Sidecar 负责与控制面直接通信并接收各种流量管控规则。以下是基本部署架构图，Dubbo ThinSDK 与 Sidecar 部署在同一个 Pod 或容器中，通过在外围部署一个独立的控制平面，实现对流量和治理的统一管控。控制面与 Sicecar 之间通过图中虚线所示的 xDS 协议进行配置分发，而 Dubbo 进程间的通信不再是直连模式，转而通过 Sidecar 代理，Sidecar 拦截所有进出流量，并完成路由寻址等服务治理任务。&lt;/p>
&lt;p>&lt;img src="https://dubbo.apache.org/imgs/v3/mesh/dubbo-sidecar.png" alt="dubbo-sidecar">&lt;/p>
&lt;p>社区推荐选型 Envoy 作为 Sidecar，通信协议使用 Triple 以获得更好的网关穿透性与性能体验。对于暂时无法升级 Triple 的仍在使用 Dubbo2 协议用户来说，可参考 Envoy、Aeraki Mesh 提供的 Dubbo2 协议支持方案。&lt;/p>
&lt;p>ThinSDK + Sidecar 模式的 Mesh 架构有很多优势，如平滑升级、多语言、业务侵入小等，但也带来了一些额外的问题，比如：&lt;/p>
&lt;ul>
&lt;li>Sidecar 通信带来了额外的性能损耗，这在复杂拓扑的网络调用中将变得尤其明显。&lt;/li>
&lt;li>Sidecar 的存在让应用的声明周期管理变得更加复杂。&lt;/li>
&lt;li>部署环境受限，并不是所有的环境都能满足 Sidecar 部署与请求拦截要求。&lt;/li>
&lt;/ul>
&lt;p>详细方案设计与示例请参考&lt;/p>
&lt;ul>
&lt;li>&lt;a href="../../tasks/mesh/dubbo-mesh">Dubbo ThinSDK Proposal&lt;/a>&lt;/li>
&lt;li>&lt;a href="../../tasks/mesh/dubbo-mesh">使用示例&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="dubbo-proxyless-mesh">Dubbo Proxyless Mesh&lt;/h3>
&lt;p>作为 ThinSDK + Sidecar 模式的补充，Dubbo 社区自很早之前就做了 Dubbo 直接对接到控制面的设想与思考，也就是当前所说的 Proxyless Mesh 模式。Proxyless 模式使得微服务又回到了 2.x 时代的部署架构。如下图所示，和我们上面看的 Dubbo 经典服务治理模式非常相似，所以说这个模式并不新鲜， Dubbo 从最开始就是这么样的设计模式。但相比于 Mesh 架构，Dubbo2 并没有强调控制面的统一管控，而这点恰好是 Service Mesh 所强调的，强调对流量、可观测性、证书等的标准化管控与治理，也是 Mesh 理念先进的地方。&lt;/p>
&lt;p>&lt;img src="https://dubbo.apache.org/imgs/v3/mesh/dubbo-proxyless.png" alt="dubbo-proxyless">&lt;/p>
&lt;p>通过不同语言版本的 Dubbo3 SDK 直接实现 xDS 协议解析，Dubbo 进程可以与控制面（Control Plane）直接通信，进而实现控制面对流量管控、服务治理、可观测性、安全等的统一管控，规避 Sidecar 模式带来的性能损耗与部署架构复杂性。&lt;/p>
&lt;blockquote>
&lt;p>Proxyless 模式同时支持 Dubbo2、Triple 协议，但只支持应用级服务发现的地址模型。&lt;/p>
&lt;/blockquote>
&lt;p>在 Dubbo3 Proxyless 架构模式下，Dubbo 进程将直接与控制面通信，Dubbo 进程之间也继续保持直连通信模式，我们可以看出 Proxyless 架构的优势：&lt;/p>
&lt;ul>
&lt;li>没有额外的 Proxy 中转损耗，因此更适用于性能敏感应用&lt;/li>
&lt;li>更有利于遗留系统的平滑迁移&lt;/li>
&lt;li>架构简单，容易运维部署&lt;/li>
&lt;li>适用于几乎所有的部署环境&lt;/li>
&lt;/ul>
&lt;p>详细方案设计与示例请参考&lt;/p>
&lt;ul>
&lt;li>&lt;a href="../../tasks/mesh/dubbo-mesh">Dubbo Proxyless Mesh&lt;/a>&lt;/li>
&lt;li>&lt;a href="../../tasks/mesh/dubbo-mesh">使用示例&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="dubbo-控制面治理规则">Dubbo 控制面治理规则&lt;/h3>
&lt;p>TBD&lt;/p>
&lt;p>Dubbo SDK 提供了非常灵活的配置来控制服务治理行为，如接口粒度的服务地址发现能力、接口粒度的配置同步等，这些能力让应用的开发和部署更加灵活。而在通用的 Mesh 部署方案或产品下一些高级功能可能受限，从总体上影响了易用性与灵活性。为此 Dubbo 计划提供自研控制面产品，以最大化的在 Mesh 体系发挥 Dubbo3 能力。&lt;/p></description></item></channel></rss>